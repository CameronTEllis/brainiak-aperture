{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Topographic Factor Analysis\n",
    "By Jeremy R. Manning ([jeremy.r.manning@dartmouth.edu](mailto:jeremy.r.manning@dartmouth.edu)) and Paxton C. Fitzpatrick ([Paxton.C.Fitzpatrick@dartmouth.edu](mailto:Paxton.C.Fitzpatrick@dartmouth.edu))\n",
    "\n",
    "# Overview\n",
    "\n",
    "In this demonstration, we'll be using the [BrainIAK](https://brainiak.org/) Python toolbox to apply [Hierarchical Topographic Factor Analysis (HTFA)](https://www.sciencedirect.com/science/article/abs/pii/S1053811918300715) to an fMRI dataset.\n",
    "\n",
    "The demo will comprise three main steps:\n",
    "1. Apply HTFA to the dataset to discover a basis set of network \"nodes\"\n",
    "2. Apply a [dynamic correlation model](https://www.biorxiv.org/content/10.1101/763821v1.full.pdf) to the HTFA fits to characterize the network dynamics\n",
    "3. Visualize the network dynamics in two ways:\n",
    "  - An animated [chord diagram](https://en.wikipedia.org/wiki/Chord_diagram)\n",
    "  - An animated brain plot\n",
    "  \n",
    "# Getting started\n",
    "\n",
    "The easiest way to run this notebook is to download the corresponding Docker image.  That will install the necessary toolboxes and dependencies, and it will also download the data you'll be analyzing.\n",
    "\n",
    "To build the docker image, navigate to this folder and run:\n",
    "```\n",
    "docker build --rm --force-rm -t htfa .\n",
    "```\n",
    "\n",
    "To start the image for the first time, run:\n",
    "```\n",
    "docker run -it -p 8888:8888 --name htfa -v $PWD:/mnt htfa\n",
    "```\n",
    "and on subsequent times, run:\n",
    "```\n",
    "docker start htfa && docker attach htfa\n",
    "```\n",
    "\n",
    "When the docker image is started, it will automatically start a Jupyter notebook server.  Copy and paste the *third* link into a browser to interact with this notebook.\n",
    "\n",
    "To stop running the container, run:\n",
    "```\n",
    "docker stop htfa\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization\n",
    "\n",
    "Import libraries and helper functions and load the [dataset](https://drive.google.com/open?id=1IBA39ZZjeGS1u_DvZdiw1AZZQMS3K5q0).  The dataset we'll be analyzing is a subset of the story listening dataset collected by [Simony et al. (2016)](https://www.nature.com/articles/ncomms12141)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the next two lines suppress a (meaningless) warning about the graphics backend\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from brainiak.factoranalysis.htfa import HTFA\n",
    "import holoviews as hv\n",
    "import nibabel as nb\n",
    "import nilearn as nl\n",
    "import nltools as nlt\n",
    "import timecorr as tc\n",
    "import seaborn as sns\n",
    "\n",
    "from mpi4py import MPI\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import os, sys\n",
    "from glob import glob as lsdir\n",
    "\n",
    "from helpers import nii2cmu, cmu2nii, animate_chord, animate_connectome\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "intact = lsdir('/data/Pieman2/sub-*/func/*intact*.nii.gz')\n",
    "scrambled = lsdir('/data/Pieman2/sub-*/func/*word*.nii.gz')\n",
    "\n",
    "combined_fnames = list.copy(intact)\n",
    "combined_fnames.extend(scrambled)\n",
    "mask = '/data/Pieman2/masks/avg152T1_gray_3mm.nii.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit HTFA to data\n",
    "\n",
    "First we need to convert the dataset into [CMU format](http://www.cs.cmu.edu/afs/cs/project/theo-73/www/science2008/README-data-documentation.txt).  Consistent with CMU format, nilearn expects the data matrices to have number-of-timepoints rows and number-of-voxels columns.  BrainIAK expects the data in the transpose of that format-- number-of-voxels by number-of-timepoints matrices. We can easily convert between the two formats using the map function.\n",
    "\n",
    "After wrangling the data, we'll fit HTFA to the full dataset to identify network nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data to CMU format\n",
    "cmu_data = [nii2cmu(f) for f in combined_fnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to HTFA format\n",
    "htfa_data = [{'R': x['R'], 'Z': x['Y'].T} for x in cmu_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure MPI:\n",
    "#  - if the local environment supports MPI, do computations in parallel (fast!)\n",
    "#  - if MPI is not supported, do computations in serial (slower)\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "size = comm.Get_size()\n",
    "\n",
    "if rank == 0:\n",
    "    import logging\n",
    "    logging.basicConfig(stream=sys.stdout, level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up HTFA model\n",
    "K = 25 #number of nodes; decrease to speed up analysis, increase for greater accuracy (min: 1)\n",
    "nvoxels, ntimepoints = htfa_data[0]['Z'].shape\n",
    "\n",
    "htfa = HTFA(K=K,\n",
    "            n_subj=len(htfa_data),\n",
    "            max_global_iter=5, #decrease for speed, increase for greater accuracy (min: 1)\n",
    "            max_local_iter=2,  #decrease for speed, increase for greater accuracy (min: 1)\n",
    "            voxel_ratio=0.5,   #decrease for speed, increase for greater accuracy (positive; max: 1.0)\n",
    "            tr_ratio=0.5,      #decrease for speed, increase for greater accuracy (positive; max: 1.0)\n",
    "            max_voxel=int(nvoxels*0.05), #decrease for speed, increase for greater accuracy (max: number of voxels)\n",
    "            max_tr=int(ntimepoints*0.1), #decrease for speed, increase for greater accuracy (max: number of TRs)\n",
    "            verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:brainiak.factoranalysis.tfa:TFA converged at 0 iteration.\n",
      "INFO:brainiak.factoranalysis.tfa:TFA converged at 1 iteration.\n",
      "INFO:brainiak.factoranalysis.tfa:TFA converged at 0 iteration.\n",
      "INFO:brainiak.factoranalysis.tfa:TFA converged at 0 iteration.\n",
      "INFO:brainiak.factoranalysis.tfa:TFA converged at 1 iteration.\n",
      "INFO:brainiak.factoranalysis.tfa:TFA converged at 1 iteration.\n",
      "INFO:brainiak.factoranalysis.tfa:TFA converged at 1 iteration.\n",
      "INFO:brainiak.factoranalysis.tfa:TFA converged at 1 iteration.\n",
      "INFO:brainiak.factoranalysis.tfa:TFA converged at 0 iteration.\n",
      "INFO:brainiak.factoranalysis.tfa:TFA converged at 0 iteration.\n",
      "INFO:brainiak.factoranalysis.tfa:TFA converged at 0 iteration.\n",
      "INFO:brainiak.factoranalysis.tfa:TFA converged at 1 iteration.\n",
      "INFO:brainiak.factoranalysis.tfa:TFA converged at 0 iteration.\n",
      "INFO:brainiak.factoranalysis.tfa:TFA converged at 0 iteration.\n",
      "INFO:brainiak.factoranalysis.tfa:TFA converged at 0 iteration.\n",
      "INFO:brainiak.factoranalysis.tfa:TFA converged at 0 iteration.\n",
      "INFO:brainiak.factoranalysis.tfa:TFA converged at 0 iteration.\n",
      "INFO:brainiak.factoranalysis.tfa:TFA converged at 0 iteration.\n",
      "INFO:brainiak.factoranalysis.tfa:TFA converged at 1 iteration.\n"
     ]
    }
   ],
   "source": [
    "# fit HTFA to htfa_data\n",
    "htfa.fit([x['Z'] for x in htfa_data], [x['R'] for x in htfa_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting HTFA global and local hub locations\n",
    "\n",
    "We'll generate a plot where the global hub locations are shown in black, and each subject's \"local\" hub locations are shown in color (where each subject is assigned a different color). The hubs should be in similar (but not identical) locations across subjects.  Note: if the number of hubs or iterations is small, or if the voxel and/or timepoint subsampling is high, the final result will tend to be close to the initialized values (with little variation across subjects).  Increase `max_global_iter`, `max_local_iter`, `max_voxel`, and `max_tr` to achieve greater accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the node display properties\n",
    "colors = np.repeat(np.vstack([[0, 0, 0], sns.color_palette(\"Spectral\", htfa.n_subj)]), K, axis=0)\n",
    "colors = list(map(lambda x: x[0], np.array_split(colors, colors.shape[0], axis=0))) #make colors into a list #FIXME: simplify this...\n",
    "sizes = np.repeat(np.hstack([np.array(50), np.array(htfa.n_subj*[20])]), K)\n",
    "\n",
    "#extract the node locations from the fitted htfa model\n",
    "global_centers = htfa.get_centers(htfa.global_posterior_)\n",
    "local_centers = [htfa.get_centers(x) for x in np.array_split(htfa.local_posterior_, htfa.n_subj)]\n",
    "centers = np.vstack([global_centers, np.vstack(local_centers)])\n",
    "\n",
    "#make the plot\n",
    "niplot.plot_connectome(np.eye(K*(1 + htfa.n_subj)), centers, node_color=colors, node_size=sizes);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute dynamic correlations\n",
    "\n",
    "The timeseries of activations for each node, for each participant provide a low-dimensional embedding of the original data that we can use to efficiently examine dynamic connectivity patterns.  Obtaining these embeddings requires some data wrangling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The per-timepoint node weights (for all of the subjects) are stored in a single vector, htfa.local_weights_.\n",
    "#(This is to enable message passing via MPI.)  We need to split up the weights by subject,\n",
    "#and then reshape each subject's node weights into a K by n_timepoints matrix (which we\n",
    "#take the transpose of, for convenience later on).\n",
    "n_timepoints = [x['Z'].shape[1] for x in htfa_data] #number of timepoints for each person\n",
    "inds = np.hstack([0, np.cumsum(np.multiply(K, n_timepoints))])\n",
    "W = [htfa.local_weights_[inds[i]:inds[i+1]].reshape([K, n_timepoints[i]]).T for i in np.arange(htfa.n_subj)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out intact vs. word subjects\n",
    "\n",
    "# compute dynamic ISFC for intact, (word) scrambled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate animated chord diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intact\n",
    "\n",
    "# scrambled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate animated brain network plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intact\n",
    "\n",
    "# scrambled"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "data_visualization.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
