{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functional Alignment\n",
    "This notebook describes an example how to use the methods for functional alignment. BrainIAK includes several options that depend on the user needs. The most basic method is the [Shared Response Model](https://papers.nips.cc/paper/5855-a-reduced-dimension-fmri-shared-response-model) (SRM). The main idea behind this method is to capture what is common across participants performing the same task. Given data that is synchronized in the temporal dimension across a group of subjects, SRM computes a low dimensional *shared* feature subspace common to all subjects. The method also constructs orthogonal weights to project from the shared subspace to each subject voxel space.\n",
    "\n",
    "The functional alignment module simplifies the import and interchange among these methods. The module includes the following variations of SRM:\n",
    "* SRM: A probabilistic version of SRM\n",
    "* DetSRM: A deterministic version of SRM\n",
    "* RSRM: Robust SRM for better filtering idiosyncratic components and outliers in data\n",
    "* SSSRM: Semi-Supervised SRM for introducing partial labelled data  \n",
    "* FastSRM: A faster version that projects the data into  \n",
    "* @SAM Conectivity-SRM?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import scipy.io\n",
    "from scipy.stats import stats\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import NuSVC\n",
    "import numpy as np\n",
    "import brainiak.funcalign.srm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @SAM: Here we need to describe the data and load it\n",
    "# I am assumming that we load it in a variable named \"data\" and it is a list with each subject's data as a matrix\n",
    "# data[i] is data for ith subject with dimensions V_i x T, with V_i the number of voxels \n",
    "# for subject i and T the number of TRs\n",
    "n_subjects = 0 # Number of subjects\n",
    "n_trs = 0 # Total TRs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once data is loaded, we divide the data into two halves for a two fold validation.\n",
    "We will use one half for training SRM and the other for testing its performance.\n",
    "Then, we normalize the data each half."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "test_data = []\n",
    "for subject in range(n_subjects):\n",
    "    # Take the first half of TRs as training\n",
    "    train_data.append(np.nan_to_num(stats.zscore(data[subject][:, :n_trs//2], axis=1, ddof=1)))\n",
    "    # Take the second half of TRs as testing\n",
    "    test_data.append(np.nan_to_num(stats.zscore(data[subject][:, -(n_trs//2):], axis=1, ddof=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SRM: Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we train the SRM model on the training data. \n",
    "Therefore, we need to define the dimension of the desired feature space.\n",
    "A good methodology to find a good value is to apply cross-validation.\n",
    "\n",
    "Also, we need to define the number of iterations that the SRM algorithm should run. Ideally, this number should be high enough so the algorithm converges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = 50  # The dimension of the deature space\n",
    "n_iter = 20  # Number of iterations to perform.\n",
    "\n",
    "# Create an SRM object\n",
    "srm = brainiak.funcalign.srm.SRM(n_iter=n_iter, features=features)\n",
    "\n",
    "# Fit the SRM data\n",
    "print('Fitting SRM')\n",
    "srm.fit(train_data)\n",
    "print('SRM has been fit')\n",
    "print(f'Share response shape: {srm.s_.shape[0]} Features x {srm.s_.shape[1]} Time-points')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training SRM, we obtain a shared response $S$ that contains the values of the features for each TR, and a set of weight matrices $W_i$ that can project from the shared subspace to a specific subject voxel space.\n",
    "\n",
    "Let us check the orthogonal property of the weight matrix $W_i$ for a subject.\n",
    "We visualize $W_i^TW_i$ that should be the identity $I$ matrix of shape equal to the number of features we selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 0\n",
    "print(f'Weight matrix shape: {srm.w_[subject].shape[0]} Voxels x {srm.w_[subject].shape[1]} Features')\n",
    "\n",
    "plt.title(f'Weight matrix test for orthogonality for subject {subject}') \n",
    "plt.figure()\n",
    "plt.imshow(srm.w_[0].T.dot(srm.w_[0]))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the performance of SRM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we trained SRM above, we learned the weight matrices $W_i$ and the shared response $S$ for the training data. The weight matrices further allow us to convert new data to the shared feature space. We call the `transform` function to convert new data for each subject. Then, we normalize for additional analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_test = srm.transform(test_data)\n",
    "\n",
    "# Zscore the transformed test data\n",
    "for subject in range(num_subs):\n",
    "    shared_test[subject] = stats.zscore(shared_test[subject], axis=1, ddof=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
